<p><img src="titlepage.png" alt="image" /> <span class="citation" data-cites="titlepageimage"></span></p>
<p>Hiermit versichere ich, dass ich die Arbeit selbstständig verfasst, dass ich keine anderen Quellen und Hilfsmittel als die angegebenen benutzt und die Stellen der Arbeit, die anderen Quellen dem Wortlaut oder Sinn nach entnommen sind, in jedem einzelnen Fall unter Angabe von Quellen kenntlich gemacht habe.</p>
<h1 id="einführung">Einführung</h1>
<p>Im Enterprise und Forschungsbereich spielt Machine Learning schon seit vielen Jahren eine bedeutende Rolle. Doch wie kann es dem Endnutzer, zum Beispiel in mobilen Apps, weiterhelfen?</p>
<h2 id="wahl-des-themas">Wahl des Themas</h2>
<p>Seitdem ich im Jahr 2017 meinen ersten richtigen Kontakt mit der Programmierung von Microcontrollern (Arduinos) hatte, habe ich mich stark für die Entwicklung von Software interessiert. Dies war ein guter Einstieg, da man dort schnell und recht einfach Ergebnisse, wie zum Beispiel eine blinkende LED, erzielt.</p>
<p>Auch habe ich mich seitdem immer für die “neuen großen Technologien” wie Blockchain oder Machine Learning interessiert. Zum Thema Machine Learning habe ich zuvor noch nicht viel gemacht, daher ergriff ich die Chance dieses Jahr meine Facharbeit über dieses Thema zu schreiben.</p>
<blockquote>
<p>AI is profound, and we are at a point—and it will get better and better over time—where the GPU is getting so powerful there’s so much capability to do unbelievable things. What all of us have to do is to make sure we are using AI in a way that is for the benefit of humanity, not to the detriment of humanity.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>Ich persönlich finde dieses Zitat sehr wichtig; es ist jetzt über 3 Jahre alt und bis heute hat sich enorm viel in diesem Bereich getan. Wir haben nun GPU’s, welche speziell auf mathematische Berechnungen mit Tensoren optimiert sind und so das Trainieren von Neuronalen Netzen um ein Vielfaches beschleunigen.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Des weiteren ist es mir, genauso wie Cook, wichtig, diese mächtige Technologie nicht zu missbrauchen<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, sondern gute Dinge mit ihr zu schaffen: wie beispielsweise im Bereich der Medizin. In diesem Bereich wurden schon viele beachtliche Anwendungszwecke gefunden, so hat Google’s Tochterfirma DeepMind im Dezember 2020 eine KI<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> präsentiert, welche das Falten von Proteinen akkurat prognostizieren kann; dies war vorher nur sehr langsam und deutlich ungenauer möglich.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<h2 id="ziel-der-arbeit">Ziel der Arbeit</h2>
<p>Mein persönliches Ziel ist es, mehr über den Aufbau von Neuronalen Netzen und die Funktionsweise von Machine Learning zu lernen. Außerdem möchte ich auch ein praktisches Ergebniss haben, dafür habe ich im Kapitel !TODO! eine App entwickelt, welche dem Nutzer mehr Informationen über Produkte beim einkaufen liefern soll.</p>
<h1 id="neuronale-netzwerke">Neuronale Netzwerke</h1>
<h2 id="geschichte">Geschichte</h2>
<p>Im Jahr 1943 wurde die erste Arbeit darüber geschrieben, wie Neuronen im Gehirn funktionieren könnten und die Autoren Warren McCulloch und Walter Pitts experimentierten sogar damit diese mit elektronischen Schaltkreisen nachzubauen.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> In den 1950er Jahren haben Forscher von IBM daran gearbeitet ein NN<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> mit einem Computer zu simulieren. Der Versuch scheiterte allerdings.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> Immer wieder gab es kleinere Forschungsprojekte, ein sehr großer Durchbruch war aber 1975 die Entwicklung eines “Backpropagation” Algorithmus durch den Wissenschaftler Paul Werbos. Ähnliche Algorithmen wurden wiederholt und unabhängig entwickelt, aber Werbos’ Algorithmus war der erste mit großer Bedeutung.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Das Prinzip des Algorithmus wird auch heute noch verwendet, es ist dieser Algorithmus der dem Neuronalen Netzwerk das selbstständige Lernen ermöglicht.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<h3 id="zeitstrahl">Zeitstrahl</h3>
<p><span>1940</span><span>2020</span></p>
<h2 id="aufbau">Aufbau</h2>
<h2 id="funktionsweise">Funktionsweise</h2>
<h3 id="trainieren---backpropagation">Trainieren - Backpropagation</h3>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><span class="citation" data-cites="timcookquote"></span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation" data-cites="nvidiatensorcores"></span><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Beispiel: Autonome Waffen, wie Drohnen, welche Ziele autonom erfassen können<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Künstliche Intelligenz<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><span class="citation" data-cites="deepmindprotein"></span><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p><span class="citation" data-cites="alogicalcalculus"></span><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Kurzform für Neuronales Netzwerk, wird ab jetzt weiterhin verwendet.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p><span class="citation" data-cites="nnhistory"></span><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p><span class="citation" data-cites="paulwerbosbackpropagation"></span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>siehe Kapitel <a href="#funktionsweise" data-reference-type="ref" data-reference="funktionsweise">2.3</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
