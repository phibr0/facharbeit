\section{Neuronale Netzwerke}

\subsection{Wichtigste Ereignisse in der Geschichte}

Im Jahr 1943 wurde die erste Arbeit darüber geschrieben, wie Neuronen im Gehirn funktionieren könnten und die Autoren Warren McCulloch und Walter Pitts experimentierten sogar damit diese mit elektronischen Schaltkreisen nachzubauen.\footnote{\cite[]{alogicalcalculus}}

In den 1950er Jahren haben Forscher von IBM daran gearbeitet ein Neuronales Netzwerk mit einem Computer zu simulieren. Der Versuch scheiterte allerdings.\footnote{\cite[Absatz 3]{nnhistory}}

Immer wieder gab es kleinere Forschungsprojekte, ein sehr großer Durchbruch war aber 1975 die Entwicklung eines "`Backpropagation"' Algorithmus durch den Wissenschaftler Paul Werbos. Ähnliche Algorithmen wurden wiederholt und unabhängig entwickelt, aber Werbos' Algorithmus war der erste mit großer Bedeutung.\footnote{\cite[]{paulwerbosbackpropagation}} Das Prinzip des Algorithmus wird auch heute noch verwendet, es ist dieser Algorithmus der dem Neuronalen Netzwerk das selbstständige Lernen ermöglicht.\footnote{Genaueres in Kapitel \ref{funktionsweise}}

In 1998 veröffentlichte Yann LeCun und sein Team eine Arbeit über die Anwendung eines "`Convolutional Neural Networks\footnote{Ab jetzt als CNN bezeichnet}"' zur Erkennung von geschriebenen Zeichen in einem Dokument.\footnote{\cite[]{cnnhistory}} Diese Arbeit gilt als Ursprung des, für beispielsweise Bilderkennungs Software gut geeignete, CNNs und Weiterentwicklungen werden auch heute noch verwendet.

Obwohl ein großes Potenzial erkannt wurde, war es über die nächsten Jahre wieder recht still. Der nächste große Durchbruch passierte in 2012 als Geoffrey Hinton ein Modell entwickelte, was die Fehlerquote in einer öffentlichen Challenge für Bilderkennung beinahe halbierte.\footnote{\cite[]{geoffrey}} Der Grund dafür waren mehrere fundamentale Neuerungen aus dem Bereich Deep Learning; die wahrscheinlich größte Änderung: Starke Parallelisierung des Backpropagation-Prozesses, durch Verschiebung der Last von der CPU auf die GPU. Aufgrund der starken Überlegenheit eines Grafikprozessors in parallelisierten Prozessen, wie die benötigten Tensormultiplikationen durch die deutlich größere Anzahl an (dafür schwächeren) Kernen im Vergleich zu einer herkömmlichen CPU, kann ein Neuronales Netzwerk mehrere hundertmal schneller trainiert werden.

Heute gibt es (vergleichsweise) simple Frameworks, wie das im Jahr 2015 erschienende TensorFlow oder PyTorch aus 2016, welche das erstellen, trainieren und verwenden von Neuronales Netzwerk enorm vereinfachen. Ihr Funktionsumfang wächst durch die große Open-Source Community ständig.

%Sind die Zitate okay?

\begin{figure}[h]
    \begin{chronology}[10]{1940}{2020}{\textwidth}
        \event{1943}{Erste Arbeit und Experimente}
        \event[1950]{1960}{Bemühungen, ein NN\footnote{Kurzform für "`Neuronales Netzwerk"'} digital umzusetzen}
        \event{1975}{Backpropagation Algorithmus}
        \event{1998}{Erfindung des CNNs}
        \event[2015]{2020}{Entwicklung versch. Frameworks}
    \end{chronology}
    \caption[Zeitstrahl]{Zeitstrahl von 1940 bis 2020 mit den wichtigsten Ereignissen der Entwicklung künstlicher Neuronaler Netzwerke}
\end{figure}

\subsection{Aufbau}

\begin{wrapfigure}{r}{87mm}
    \input{lib/tikz/nn.tex}
    \caption[Aufbau]{Vereinfachter Aufbau eines Neuronales Netzwerk}
\end{wrapfigure}

In Abbildung 2 sieht man den Aufbau eines herkömmlichen künstlichen Neuronalen Netzwerks, so wie es noch vor 40 Jahren verwendet wurde. In der Grafik erkennt man drei Layer mit einer x-beliebigen Anzahl Neuronen, welche untereinander mit jeweils allen Neuronen der vorigen und nächsten Layer verbunden sind. Im Gegensatz zu einem biologischen Neuron, welches nur aktiv oder inaktiv sein kann, kann ein künstliches Neuron einen Zustand in Form eines Wertes von ${0 \leq x \leq 1}$ haben. Jede Verbindung hat einen Weight Paramter und auch jedes Neuron hat einen Bias. Die Anzahl der Hidden Layer kann an das Ziel angepasst und ausgewählt werden und auch die Anzahl der einzelnen Neuronen ist erstmal beliebig, als Faustregel für gute Ergebnisse gilt aber:

\begin{itemize}
    \item Die Anzahl der Neuronen in dem Hidden Layer sollte zwischen der Größe des Input und Output Layers liegen.
    \item Die Anzahl der Neuronen in dem Hidden Layer sollte etwa $\frac{2}{3}$ der Größe des Input Layers plus der Größe des Output Layers entsprechen.
    \item Die Anzahl der Neuronen in einem Hidden Layer sollte weniger als die Hälfte der Größe des Input Layers sein.\footnote{\cite[Alle drei Faustregeln]{heaton}}
\end{itemize}

\subsubsection{Erstellung eines Neuronalen Netzwerks anhand eines Beispiels}

Als Beispiel für ein Neuronales Netzwerk, welches darauf ausgelegt ist, geschriebene Ziffern aus Bildern mit 24x24 Pixeln und nur Graustufen zu erkennen wäre dann: Ein Input Layer mit $24^2$ Neuronen, jeweils für jeden Pixel, welche jeweils eine Aktivierung zwischen 0 (komplett weiß) und 1 (komplett schwarz) haben können, eines. Genau 10 Neuronen im Output Layer, für jedes Zahlzeichen eines. Schließlich muss die Anzahl der Hidden Layer und Neuronen festgelegt werden. Ich wähle als Beispiel 2 Layer mit jeweils 16 Neuronen, die Neuronen-Anzahl kann aber auch unterschiedlich sein. Auch die Weights und Biases werden zunächst zufällig ausgewählt, die Werte werden dann später im Trainingsprozess\footnote{siehe Kapitel \ref{backpropagation}} angepasst. Die Eingabe in das Netzwerk ist also ein zweidimensionaler Tensor, oder auch eine Matrix, mit den Bilddaten und die Ausgabe des Netzwerks ist ein eindimensionaler Tensor, oder auch ein Vektor, mit den Prognosen.

\begin{equation}
    \begin{bmatrix}
        i_{0,0}  & \ldots & i_{0,23}  \\
        \vdots   & \ddots & \vdots    \\
        i_{23,0} & \ldots & i_{23,23}
    \end{bmatrix}
    \Longrightarrow
    \text{Hidden Layer}
    \Longrightarrow
    \begin{bmatrix}
        o_0    \\
        \vdots \\
        o_9
    \end{bmatrix}
\end{equation}

\subsection{Funktionsweise} \label{funktionsweise}

\setlength{\belowcaptionskip}{-10pt}
\begin{wrapfigure}{r}{60mm}
    \resizebox{6cm}{!}{\input{lib/tikz/sigmoid.tex}}
    \caption[Sigmoid]{Die Sigmoidfunktion}
    \label{sigmoid}
\end{wrapfigure}
\setlength{\belowcaptionskip}{0pt}

Ein Neuronales Netzwerk kann man sich eigentlich als eine große verschachtelte mathematische Funktion vorstellen. In dem zuvor genannten Beispiel wäre es eine Funktion mit 576 Variablen und 10 Ergebnissen. Gibt man dieser Funktion nun ein Bild, beziehungsweise 576 Werte als Input, so werden von links nach rechts alle Weights $w$ und Biases $b$ zusammen mit dem vorigen Aktivierungswerten $a$ berechnet. Da ein Neuron aber nur Werte im Bereich $0\leq x \leq 1$ haben kann\footnote{\cite{3blue1brown}}, so wird das Ergebniss noch mithilfe einer Aktivierungsfunktion in diesen Bereich umgewandelt.\footnote{\cite{googleMlGlossar} Schlüsselwort: Activation Function} Eine früher Häufig verwendete Funktion ist dabei die Sigmoidfunktion, siehe Abbildung \ref{sigmoid}.\footnote{\cite{3blue1brown}} Es gibt aber auch noch eine Vielzahl weiterer Funktionen, wie die heute häufig verwendete ReLU Funktion\footnote{siehe Anhang \ref{anhang:weitereaktivierungsfunktionen}}, welche den Trainingprozess durch die einfachere Funktion beschleunigt.\footnote{\cite{nnfs} Seite 76 folgende} Die daraus resultierende Funktion würde in etwa so aussehen:\footnote{\cite{nnfs} Seite 185}

\begin{equation}\label{funktion1}
    \sigma(w_1a_1+w_2a_2+w_3a_3+ \ldots +w_na_n+b)
\end{equation}

Um mit dieser Formel alle Aktivierungen auf einmal berechnen zu können verwendet man folgende Funktion, in welcher alle Weights und Biases in Spalten-Vektoren zusammengefasst werden. Die Hochzeichen sind keine Exponenten sondern gelten als Bezeichnung für den Layer, hier beispielsweise 0 und 1. Das Ergebniss dieser Funktion ist ein Vektor mit allen Aktivierungen des darauf folgenden Layers.

\begin{equation}\label{funktion2}
    \sigma
    \begin{pmatrix}
        \begin{bmatrix}
            w_{0,0} & w_{0,1} & \ldots & w_{0,n} \\
            w_{1,0} & w_{1,1} & \ldots & w_{1,n} \\
            \vdots  & \vdots  & \ddots & \vdots  \\
            w_{k,0} & w_{k,1} & \ldots & w_{k,n}
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
            a_0^{(0)} \\a_1^{(0)}\\\vdots\\a_n^{(0)}
        \end{bmatrix}
        +
        \begin{bmatrix}
            b_0 \\b_1\\\vdots\\b_k
        \end{bmatrix}
    \end{pmatrix}
    =
    a^{(1)}
\end{equation}\footnote{Gleichungen \ref{funktion2} und \ref{funktion3} von \cite{3blue1brown}}

Auch diese Funktion kann wiederrum kompakter formuliert werden und diese Schreibweise wird auch für gewöhnlich verwendet:

\begin{equation}\label{funktion3}
    a^{(1)}=\sigma(W\cdot a^{(0)}+b)
\end{equation}\footnotemark[20]%TODO ist die Zahl noch richtig?

Theoretisch wenn ein Neuron einen hohen Aktivierungswert haben soll, wenn beispielsweise eine gerade Linie erkannt wird (um mit anderen Neuronen zusammen im späteren Verlauf aus den Mustern ganze Ziffern zu erkennen), so müssen die Weights der zu dem Neuron führenden Verbindungen alle möglichst niedrige Aktivierungen haben, ausser an den Stellen an denen die Linie sich befinden soll. Um sicherzustellen, dass es sich wirklich um eine gerade Linie handelt befindet sich direkt über dem Strich ein Bereich in dem keine Aktivierungen sein sollten, dieser ist rot markiert. Das erkennt man in Abbildung \ref{examples} sehr gut. In a erkennt man die zu erkennende Linie und in b sieht man die zugehörigen Weights der Input Nodes zu dem Neuron. Dabei stellt grün positive Weights da, rot negative und Weiß/Transparent ist 0. Der Bias des Neurons stellt eine Zusätzliche Hürde oder eine Verstärkung da, was auch in Formel \ref{funktion1} als $b$ sichtbar ist.

\begin{figure}[H]
    \centering
    \subfloat[\centering Zu erkennendes Bild]{\input{lib/tikz/sevenexample.tex}}%
    \qquad
    \subfloat[\centering Benötigte Weights]{\input{lib/tikz/sevenweightsexample.tex}}
    \caption[Visualisierung]{Visualisierung der gewünschten Formen a und die dazugehörigen Weights b (jeweils abgeschnitten)}
    \label{examples}%
\end{figure}

\subsubsection{Trainieren des Neuronalen Netzwerks} \label{backpropagation}

Dieser Prozess ist der wichtigste. Durch das Trainieren erzielt ein Neuronales Netzwerk den Effekt des selbstständigen Lernens. Und da die Werte der Weights und Biases zunächst zufällig ausgewählt wurden, muss das Netzwerk trainiert werden um nicht völligen Unsinn auszugeben.\footnote{Ein Code Beispiel, wie man ein solches Netzwerk mit modernen Frameworks erstellen und trainieren würde befindet sich im Anhang \ref{anhang:colab1}.}

\paragraph{Die Cost Function}\label{paracost}

Um herauszufinden wie gut oder schlecht ein Neuronales Netzwerk arbeitet, also auf das Beispiel bezogen wie genau oder ungenau es Ziffern erkennen kann, gibt es die Cost Function. Es gibt verschiedene Arten und Möglichkeiten ähnliche Funktionen anzuwenden, hier werde ich mich allerdings auf die Minimierung der Cost Function beziehen. Als Ergebniss kommt eine einzige Zahl heraus welche hoch ist, wenn das Netzwerk schlechte Ergebnisse erzielt und gegen 0 läuft, wenn das Netzwerk sehr gute Ergebnisse liefert. Es gibt mehrere verschiedene Cost Functions, aber ich fokussiere mich erstmal auf die MSE Funktion. MSE steht für "`Mean squared Error"', sie berechnet den Cost Wert\footnote{Manchmal auch Loss genannt, meint das gleiche.} aus dem durchschnitt der Summe der Vorhersagen und den erwarteten Ergebnissen zum Quadrat:

\begin{equation}\label{costfunction}
    C = \frac{1}{m} \sum^{m}_{i=1}(x^{(i)}-y^{(i)})^2
\end{equation}

Wenn:

\begin{itemize}
    \item $i$ = Index der Trainingsdate
    \item $x$ = Vorhersage des Netzwerk
    \item $y$ = Erwartetes (richtiges) Ergebnis
    \item $m$ = Anzahl der Trainingsdaten\footnote{Formel \ref{costfunction} und Erklärung vergleiche \cite{towardsds}}
\end{itemize}

\paragraph{Gradientenabstiegsverfahren}\label{paragrad}

Leider ist es bei solch großen Funktionen nicht mehr möglich (stimmt das? !TODO!) das Globale Minimum explizit zu bestimmen.

\begin{wrapfigure}{r}{80mm}
    \input{lib/tikz/2dcost.tex}
    \caption[2dcost]{Vorgehen bei der Minimierung}
    \label{2dcost}
\end{wrapfigure}

Daher berechnet man die Steigung $\Delta C$\footnote{$C$ bezieht sich hier auf die \textbf{C}ost function} der Funktion und bestimmt anschließend die Richtung $-\Delta C$ in welche der Graph sinkt. In Abbildung \ref{2dcost} ist der Graph nur Zweidimensional und daher gibt es nur eine Richtung in welcher der Graph fallen kann. So wird die Eingabe immer weiter so verändert, dass sich die Cost Function minimiert. Dies passiert in mehreren Iterationen oder auch Epochen, in welchen die Veränderungen, also Schritte in Richtung $-\Delta C$, in Abhänigkeit von der Steigung, immer kleiner werden um einen Überschuss zu verhindern.\footnote{\cite{3blue1brown}} Das ist auch der Grund weswegen, wie in dem Ergebniss des Trainings von \ref{anhang:colab1} zu erkennen, Trainingszeiten exponentiell zur Genauigkeit ansteigen. Die Größe dieser Schritte wird auch Lernrate / Learning Rate genannt.\footnote{\cite{readthedocsgradientdescent}}

%\newpage

\begin{wrapfigure}{r}{80mm}
    \includegraphics[totalheight=9cm]{GradientDescent.png}
    \caption[3dcost]{Visualisierung des Gradientenabstiegsverfahren im dreidimensionalen Raum (\cite{3blue1brown})}
    \label{3dcost}
\end{wrapfigure}

Bei mehrdimensionalen Funktionen, wie auch den Neuronalen Netzwerken, gibt es mehr Möglichkeiten in welche Richtung der Graph am schnellsten Fallen könnte. Die oben beschriebene Technik die dafür verwendet wird nennt sich das Gradientenabstiegsverfahren. Da die Funktionen in echt allerdings deutlich komplizierter sind, gibt es sehr viele Extrema und da das Ziel ein möglichst tiefer Extrempunkt ist, versucht man zu verhindern, dass man in einem solcher hohen Minima "`stecken bleibt"'. Deswegen verwendet man meistens abgewandelte Formen des Gradientenabstiegsverfahrens, zum Beispiel mit einem Modifikator für Momentum. So fällt unter Umständen "`der Ball"' weiter in ein tieferes Minimum, was in Abbildung \ref{3dcost} zu erkennen ist. Desweiteren wird für Machine Learning fast ausschließlich "`Stochastic gradient descent"' verwendet, da das Gradientenabstiegsverfahren allein viel zu aufwendig ist. Mit dieser Form verliert man etwas Genauigkeit, der Prozess geht aber ein vielfaches schneller vonstatten. Anstatt den Gradienten von allen Trainingsdaten zusammen zu suchen, teilt man die Trainingsdaten in mehrere "`Batches"' auf und wendet auf diesen das Gradientenabstiegsverfahren an. So werden häufiger/schneller Schritte richtung Extrempunkt gemacht, diese sind dafür aber ungenauer (sie repräsentieren nicht den schnellsten Weg).\footnote{\cite{3blue1brown} und \cite{mitstochasticgd}}

\paragraph{Ketten Regel}\label{parachain}

Die Kettenregel vereinfacht das Ableiten von komplizierten Funktionen, zum Beispiel mit weiteren Funktionen im inneren. Wie man diese anwendet sieht man in Formel \ref{kettenregel}.\footnote{\cite{kettenregel}}

\begin{equation}\label{kettenregel}
    \begin{matrix}
        f(x) = u(g(x)) \\
        f'(x) = u'(g(x)) \cdot g'(x)
    \end{matrix}
\end{equation}

Dieses Verfahren wird verwendet um die Ableitungen "`verschachtelter"' Funktionen zu finden, in diesem Fall wird hiermit die Ableitung des Netzwerks und in späteren Schritten auch die Ableitung von Anteilen des Netzwerks gesucht.\footnote{\cite{chainruleml}}

\paragraph{Backpropagation}\label{backprop}

Jetzt ist klar was das Ziel des Trainingsprozesses ist, aber wie wird die Cost Function minimiert? Hier kommt der Backpropagation Algorithmus ins Spiel. In Kombination mit der Cost Function und den soeben besprochenen Verfahren bestimmt dieser Algorithmus welche und um wie viel die Weights und Biases des Neuronalen Netzwerks angepasst werden müssen. Dies passiert, wie der Name schon impliziert, rückwärts. Ziel ist es hier also den Einfluss der einzelnen Weights und Biases auf das Endergebniss herauszufinden, um so dann diese Werte anzupassen.\footnote{\cite{3blue1brown}}

Der Algorithmus berechnet also die Ableitungen der einzelnen Teilstücke des Netzwerks mithilfe der Kettenregel und ist somit in der Lage herauszufinden welche Variablen (Weights und Biases) welchen Einfluss auf das Endergebniss haben.\footnote{\cite{3blue1brown}}

\subsection{Abwandlungen}

Heute gibt es sehr viele verschiedene Abwandlungen von diesen Techniken und auch Neuronale Netzwerke, die zwar ähnlich aufgebaut sind, die besser für manche Zwecke sind als andere. Da gibt es zum Beispiel "`Convolutional Neural Networks"'\footnote{auch CNN; deutsch: \textbf{faltendes} neuronales Netzwerk}, welche besonders gut zum erkennen von Objekten in Bildern geeignet sind und daher auch eins in \ref{erstellen des modells} verwendet wird. Oder "`Long short Term memory Networks"'\footnote{auch LSTMN; deutsch: Langes \textbf{Kurzzeitgedächtnis} Netzwerk}, welche speziell auf das erkennen von Stimmen ausgelegt sind.

\subsubsection{Convolutional Neural Networks}

\begin{wrapfigure}{r}{58mm}
    \includegraphics[totalheight=3cm]{cnn2.png}
    \caption[cnn2]{Repräsentationen zweier Kreuze durch zweidimensionale Arrays}
    \label{cnn2}
    \vspace{5mm}
    \includegraphics[totalheight=3cm]{cnn3.png}
    \caption[cnn3]{Vorgehen eines CNN's}
    \label{cnn3}
    \vspace{5mm}
    \center{\includegraphics[totalheight=15mm]{filter.png}}
    \caption[filter]{Ein Filter innerhalb eines CNN's}
    \label{filter}
    \vspace{5mm}
    \center{\includegraphics[totalheight=22mm]{cnnmatrix.png}}
    \caption[matrix]{Resultierende Matrix (Abbildungen \ref{cnn2} bis \ref{cnnmatrix} von \cite{cnnexplanation})}
    \label{cnnmatrix}
\end{wrapfigure}

Convolutional Neural Networks versuchen ein Problem der normalen Neuronalen Netzwerke im Bereich der Bilderkennung zu lösen. Während in einem normalen Netzwerk die Position des zu erkennenden Objektes im Bild eine Rolle spielt, wird dies zum Großteil in einem Convolutional Neural Network durch die veränderte Funktionsweise behoben/verbessert.

Während ein Mensch diese beiden Bilder aus Abbildung \ref{cnn2} direkt und ohne jegliche Mühen als Kreuz erkennen kann, ist dies für einen Computer eine große Schwierigkeit, auch für ein herkömmliches Neuronales Netzwerk. Die Werte gleichen sich schließlich nicht wirklich.

Hier kommt dann das CNN ins Spiel welches grob beschrieben nach Eigenschaften innerhalb des Bildes sucht, dieses Vorgehen ist in Abbildung \ref{cnn3} visualisiert. Convolutional NN's nutzen "`Filtering"', ein Filter, wie in Abbildung \ref{filter} zu sehen, bewegt sich über das Bild und berechnet zu wie viel Prozent das Bild mit dem Filter übereinstimmt. Wendet man diese Berechnung, die auch "`Convolution"' genannt wird, auf das erste Bild von Abbildung \ref{cnn3} an, so resultiert eine neue kleinere Matrix, wie in Abbildung \ref{cnnmatrix} zu erkennen. Diese Matrix hat dort Werte nahe 1, wo der Filter zu 100\% mit dem Bild übereinstimmt und kleine oder sogar negative Werte in Bereichen, in denen der Filter wenig oder keine Übereinstimmung mit dem Bild aufweist.\footnote{\cite{cnnexplanation}} Zusammen mit mehreren anderen Convolutions (und daher auch Filtern) bildet sich ein Convolution Layer, welcher dann mit anderen Layern kombiniert wird, zum Beispiel herkömmliche Aktivierungsfunktionen\footnote{Bei CNN's zählen Aktivierungsfunkionen als eigene Layer; nicht zwangsläufig Teil eines Layers}, untereinander verbundene Layer\footnote{Normale Layer aus normalen NNs; Auch Dense Layer genannt} oder auch Pooling und Normalisierungs Layer, in letzterem werden einfach alle negativen Werte durch 0 ersetzt.\footnote{\cite{cnnexplanation}}

\paragraph{Pooling}

Pooling wird verwendet um die aus einem Convolutional Layer resultierende Matrix weiter zu verkleinern, um so eine Beschleunigung des Trainings und auch der Anwendung zu erzielen.

Es gibt verschiedene Arten von Pooling, zum Beispiel das maxPooling, welches immer das Maximum eines bestimmten Bereichs übernimmt. Für das Pooling muss eine "`Windows Size"' und ein "`Stride"' Wert festgelegt werden. Window Size bestimmt die Größe des Bereichs in welchem das Pooling jeweils durchgeführt wird und Stride bestimmt wie weit dieser Bereich nach jedem mal verschoben wird.
Führt man nun Pooling mit einer Window Size von 2 und einem Stride Wert von 2 auf der Matrix aus Abbildung \ref{cnnmatrix} aus, so werden zuerst die Werte aus einem 2$\cdot$2 Bereich oben links in der Matrix ausgewählt und das Maximum (hier: 1) in eine neue Matrix übernommen. Anschließend verschiebt sich der Bereich um 2 nach rechts und das Maximum wird erneut übernommen, das wird über die gesamte Matrix gemacht.\footnote{\cite{cnnexplanation}} Daraus resultiert dann folgende Matrix:

\begin{figure}[H]
    \center{\includegraphics[totalheight=3cm]{pooling.png}}
    \caption[poolingmatrix]{Resultierende Matrix des Poolings (\cite{cnnexplanation})}
    \label{poolingmatrix}
\end{figure}